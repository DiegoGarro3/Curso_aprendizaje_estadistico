{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sesion_10_nn_routines.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRgo1ME0pauT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy as sc\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pylab as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construyamos una red neuronal con una capa de entrada, una capa de salida con una red y L-1 redes ocultas.\n",
        "\n",
        "# Con m datos de entrenamientos.\n",
        "\n",
        "Para $m$ datos de entrenamiento, las expresión anteriores pueden ser resumidas en las siguientes ecuaciones\n",
        "\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix}\n",
        "z_1^{(0)}  &z_1^{(1)} & .&.& .&z_1^{(m)}\\\\\n",
        "z_2^{(0)}  &z_2^{(1)} &. &.&  .&z_2^{(m)}\\\\\n",
        ".          & .        &. & &   &.      \\\\\n",
        ".          & .        &  &. &   &.      \\\\\n",
        ".          & .        &  &  & .&      \\\\\n",
        "z_{n^{[l]}}^{(0)}&z_{n^{[l]}}^{(1)} & . & .& .& z_{n^{[l]}}^{(m)}        \\\\\n",
        "\\end{bmatrix}^{[l]}=\n",
        "\\begin{bmatrix}\n",
        "\\theta_{11} & \\theta_{12} & . & .& .& \\theta_{1n^{[l-1]}}\\\\\n",
        "\\theta_{21} & \\theta_{22} & . & .& .& \\theta_{2n^{[l-1]}}\\\\\n",
        ". & .  & . &   & & .\\\\\n",
        ". & .  &   & . & & .\\\\\n",
        ". & .  &   &  & .& .\\\\\n",
        "\\theta_{n^{[l]}1} & \\theta_{n^{[l]}2} & . & .& .& \\theta_{n^{[l]}n^{[l-1]}}\\\\\n",
        "\\end{bmatrix}^{[l]}_{n^{[l]} \\times n^{[l-1]}}\n",
        "\\begin{bmatrix}\n",
        "a_1^{(0)}  &a_1^{(1)} & .&.& .&a_1^{(m)}\\\\\n",
        "a_2^{(0)}  &a_2^{(1)} &. &.&  .&a_2^{(m)}\\\\\n",
        ".          & .        &. & &   &.      \\\\\n",
        ".          & .        &  &. &   &.      \\\\\n",
        ".          & .        &  &  & .&      \\\\\n",
        "a_{n^{[L-1]}}^{(0)}&a_{n^{[L-1]}}^{(1)} & . & .& .& a_{n^{[L-1]}}^{(m)}        \\\\\n",
        "\\end{bmatrix}^{[l-1]} +\n",
        "\\begin{bmatrix}\n",
        "b_1 \\\\\n",
        "b_2 \\\\\n",
        ". \\\\\n",
        ". \\\\\n",
        ". \\\\\n",
        "b_{n^{[l]}}\\\\\n",
        "\\end{bmatrix}^{[l]} \n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Escrito de una formas mas compacta tenemos que:\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "[ \\vec{Z}^{[l](0)},\\vec{Z}^{[l](1)},...,\\vec{Z}^{[l](m)}  ]= \\Theta^{[l]} [\\vec{A}^{[l-1](0)},\\vec{A}^{[l-1](1)},...,\\vec{A}^{[l-1](m)} ]+ \\vec{b}^{[l]}\n",
        "\\end{equation}\n",
        "\n",
        "Aplicando la funcion de activación:\n",
        "\n",
        "\\begin{equation}\n",
        "[\\vec{A}^{[l](0)},\\vec{A}^{[l](1)},...,\\vec{A}^{[l](m)} ]=f([\\vec{Z}^{[l](0)},\\vec{Z}^{[l](1)},...,\\vec{Z}^{[l](m)}  ]) \n",
        "\\end{equation}\n",
        "\n",
        "Las dimensiones de las expresiones anteriores, pueden ser resumidas en lo siguiente:\n",
        "\n",
        "$\\mathrm{dim(\\vec{\\cal{Z}}^{[l]})}=n^{[l]}\\times m $\n",
        "\n",
        "$\\mathrm{dim(\\vec{\\Theta}^{[l]})}=n^{[l]}\\times n^{[l-1]}$\n",
        "\n",
        "$\\mathrm{dim(\\vec{\\cal{A}}^{[l]})}=n^{[l-1]}\\times m $\n",
        "\n",
        "$\\mathrm{dim(\\vec{b}^{[l]})}=n^{[l]}$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c6GPOdoLjBAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Topologia de la red.\n",
        "\n",
        "1. Construir un algorítmo que permita definir una red neuronal con la topología\n",
        "deseada y la función de activación para cada capa:\n",
        "\n",
        "Topology = [n_x, n_h1, n_h2, n_h3, ...,n_y]\n",
        "\n",
        "activation=[None, relu, relu, relu, ...,sigmoid]\n",
        "\n",
        "  - $\\mathrm{n_x}$: valores de entrada\n",
        "  - $\\mathrm{n_{h1}}$: hidden layer 1 \n",
        "  - $\\mathrm{n_{h2}}$: hidden layer 2\n",
        "  - $\\mathrm{n_y}$: last layer \n",
        "\n",
        "\n",
        "\n",
        "Se sugiere para cada capa emplear programación orientada a objetos definida de la siguiente manera:\n",
        "\n",
        "```\n",
        "class layer_nn():\n",
        "  def __init__(self, act_fun, nlayer_present, nlayer_before):\n",
        "    self.theta = 2*np.random.random((nlayer_present, nlayer_before)) - 1\n",
        "    self.B = 2*np.random.random((nlayer_present,1)) - 1\n",
        "    self.act_fun = act_fun\n",
        "\n",
        "  def output(self, Z, A):\n",
        "    self.Z = Z\n",
        "    self.A = A\n",
        "\n",
        "\n",
        "\n",
        "def act_function(x, activation):\n",
        "  if activation==\"sigmoid\":\n",
        "    f = lambda x: 1/(1+np.exp(-x))\n",
        "    fp = f(x)*(1-f(x))\n",
        "    return f, fp\n",
        "  \n",
        "  elif activation == \"tanh\":\n",
        "    f = lambda x: np.tanh\n",
        "    return tanh\n",
        "  else :\n",
        "    return 0\n",
        "```\n",
        "    \n",
        "\n",
        "2. Construir un generalizacion de la red, en el que entrada el valor inicial \n",
        "y la red neuronal completa arroje la salida y la actualizacion de la red con los parametros deseados:\n",
        "\n",
        "  ```\n",
        "  A, nn = forward_pass(A0, nn_red)\n",
        "\n",
        " ```\n",
        "3. Encontrar la funcion de coste.\n",
        "\n",
        "\n",
        "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right)) \\tag{7}$$\n",
        "\n",
        "\n",
        "4. Construir un codigo que permita realizar el BackwardPropagation \n",
        "\n",
        "\n",
        "# Backward Propagation\n",
        "\n",
        "Para una capa $l$ arbitraria tenemos que:\n",
        "\n",
        "- \\begin{equation}\n",
        "d\\Theta^{[l]} =  d{\\cal Z}^{(i)[l]} Trans(A)^{(i)[l-1]} = dA^{(i)[l]} f'({\\cal Z}^{(i)[l]} ) Trans(A)^{(i)[l-1]}\n",
        "\\end{equation}\n",
        "\n",
        "- \\begin{equation}\n",
        "db^{[l]} =  d{\\cal Z}^{(i)[L]}  = dA^{(i)[l]} f'({\\cal Z}^{(i)[l]} ) \n",
        "\\end{equation}\n",
        "```\n",
        "db_L =  m_*np.sum(dZ, axis=1, keepdims=True)\n",
        "```\n",
        "Los valores de dA pueden ser escritos como:\n",
        "- \\begin{equation}\n",
        "dA^{(i)[l-1]} = \\Theta^{l} \\cdot dZ^{(i)[l]}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$ dZ^{[l]} = dA^{[l]} * f'^{[l]} (Z^{[l]}) $\n",
        "$ d\\Theta^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial \\Theta^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T} \\tag{1}$\n",
        "$ db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}\\tag{2}$\n",
        "$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = \\theta^{[l] T} dZ^{[l]} \\tag{3}$\n",
        "\n",
        "\n",
        "Para la capa L esima: \n",
        "\n",
        "```\n",
        "dAL = -(np.divide(Y, A) - np.divide(1 - Y, 1 - A))\n",
        "```\n",
        "\n",
        "# Aplicacion gradiente descendente\n",
        "\n",
        "$$ \\Theta^{[l]} = \\Theta^{[l]} - \\alpha \\text{ } d\\Theta^{[l]} \\tag{16}$$\n",
        "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} \\tag{17}$$\n"
      ],
      "metadata": {
        "id": "QPCHleHyjGL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class layer_nn():\n",
        "  \"\"\"\n",
        "  Definición de la capas de la red neuronal \n",
        "  e inicializacion de parametros. \n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,act_fun, n_layer_present, n_layer_before ):    \n",
        "    self.W = 2*np.random.random((n_layer_before,n_layer_present)) - 1\n",
        "    self.B = 2*np.random.random((n_layer_present,1)) - 1\n",
        "    self.act_fun = act_fun\n",
        "\n",
        "  def output(self, Z,A, Ap):\n",
        "    self.Z = Z\n",
        "    self.A = A\n",
        "    self.Ap = Ap\n",
        "\n",
        "  def derivates(self, dW, db):\n",
        "    self.dW = dW\n",
        "    self.db = db\n",
        "\n",
        "@np.vectorize\n",
        "def relu(x):\n",
        "  if(x>=0):\n",
        "    return x\n",
        "  else :\n",
        "    return 0\n",
        "\n",
        "@np.vectorize\n",
        "def reluP(x):\n",
        "  if(x>=0):\n",
        "    return 1\n",
        "  else :\n",
        "    return 0\n",
        "\n",
        "def sigmoide(x):      \n",
        "  f= lambda x: 1/(1+np.exp(-x))\n",
        "  return f(x)\n",
        "\n",
        "def act_function(x, activation):        \n",
        "    if activation == \"sigmoid\":\n",
        "        f = sigmoide(x)\n",
        "        fp = sigmoide(x)*(1-sigmoide(x))\n",
        "    elif activation == \"tanh\":\n",
        "        f = lambda x: np.tanh(x)\n",
        "\n",
        "    elif activation == \"relu\":\n",
        "        f = relu(x)\n",
        "        fp = reluP(x)\n",
        "    \n",
        "    return f, fp\n",
        "    \n",
        "\n",
        "def forward_pass(input, nn_red):\n",
        "  A0 = input  \n",
        "  nn_red_update = []\n",
        "  \n",
        "  for layer in nn_red: \n",
        "    Z = layer.W.T@A0 + layer.B    \n",
        "    A, Ap = act_function(Z, layer.act_fun)        \n",
        "    layer.output(Z, A, Ap)    \n",
        "    nn_red_update.append(layer)\n",
        "    A0 = A        \n",
        "  return A, nn_red_update\n",
        "\n",
        "\n",
        "def cost_Function(A, Y):\n",
        "  m = Y.shape[0]\n",
        "  m_ = 1/m\n",
        "  cost = Y*np.log(A)+(1-Y)*np.log(1-A)\n",
        "  cost = -m_*cost.sum()\n",
        "  return cost\n",
        "\n",
        "def backward_propagation(AL,Y,nn):\n",
        "  L = len(nn) - 1\n",
        "  \n",
        "  dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "  fp = nn[L].Ap \n",
        "  dZ = dAL*fp  \n",
        "  m_ = 1/np.shape(Y)[0]\n",
        "\n",
        "  dW_L = m_*dZ@nn[L-1].Ap.T\n",
        "  db_L = m_*np.sum(dZ, axis=1, keepdims=True)\n",
        "\n",
        "  nn[L].dW=dW_L\n",
        "  nn[L].db=db_L\n",
        "\n",
        "  dAL_1 = np.dot(nn[L].W, dZ)\n",
        "\n",
        "  for l in reversed(range(1,L)):\n",
        "#    dAL_1 = dAL \n",
        "    fp = nn[l].Ap\n",
        "    dZ_1 = dAL_1*fp\n",
        "    dW_L1 = m_*dZ_1@nn[l-1].Ap.T\n",
        "    db_L1 = m_*np.sum(dZ_1, axis=1, keepdims=True)\n",
        "    \n",
        "   # dAL = dAL_1.copy()\n",
        "    \n",
        "    nn[l].dW=dW_L1\n",
        "    nn[l].db=db_L1\n",
        "    dAL_1 = np.dot(nn[l].W,dZ_1)\n",
        "  return nn\n",
        "\n",
        "\n",
        "def update_params(nn, learning_rate):  \n",
        "  L=len(nn)\n",
        "  for l in range(1, L):    \n",
        "    nn[l].W = nn[l].W - learning_rate*nn[l].dW.T  \n",
        "    nn[l].B = nn[l].B - learning_rate*nn[l].db\n",
        "  return nn\n",
        "\n",
        "def red_neuronal(topology, act_fn):\n",
        "  nn_red = []\n",
        "  L = len(topology)\n",
        "  for i in range(1, L):  \n",
        "    nn_red.append(layer_nn(act_fn[i],topology[i],topology[i-1] ) )  \n",
        "  return nn_red\n"
      ],
      "metadata": {
        "id": "onnQT24Upcx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_x = 12288# -- size of the input layer\n",
        "#n_h = # -- size of the hidden layer\n",
        "n_y = 1# -- size of the output layer\n"
      ],
      "metadata": {
        "id": "q1zzHdlSpeRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "data_train= \"/content/train_catvnoncat.h5\"\n",
        "train_dataset = h5py.File(data_train, \"r\")\n",
        " \n",
        "data_test= \"/content/test_catvnoncat.h5\"\n",
        "test_dataset = h5py.File(data_test, \"r\")\n",
        "\n",
        "xtrain_classes, xtrain, train_label =\\\n",
        "train_dataset[\"list_classes\"],train_dataset[\"train_set_x\"],train_dataset[\"train_set_y\"]\n",
        "\n",
        "test_classes, xtest,test_label =\\\n",
        "test_dataset[\"list_classes\"],test_dataset[\"test_set_x\"],test_dataset[\"test_set_y\"]\n",
        "\n",
        "xtrain_= np.reshape(xtrain,(209, 64*64*3))/255\n",
        "xtest_ = np.reshape(xtest,(50, 64*64*3))/255\n",
        "\n",
        "topology = [n_x,2,2,3,1]\n",
        "act_fn   = [None,\"relu\", \"relu\", \"relu\",\"sigmoid\" ]\n",
        "\n",
        "nn_red = red_neuronal(topology, act_fn)\n"
      ],
      "metadata": {
        "id": "ySGq43G4pe0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Aini = xtrain_.T\n",
        "Y = np.array(train_label)\n",
        "A, nn = forward_pass(Aini, nn_red)\n",
        "\n",
        "Max_iter = 200\n",
        "J = np.zeros(Max_iter)\n",
        "J[0] = cost_Function(A, np.array(train_label))\n",
        "\n",
        "for i in range(1,Max_iter):\n",
        "  nn = backward_propagation(A, Y, nn)\n",
        "  nn = update_params(nn, 0.05)  \n",
        "  A, nn = forward_pass(Aini, nn)\n",
        "  J[i] = cost_Function(A, np.array(train_label))\n",
        "\n",
        "plt.plot(J,\"ro-\")\n",
        "  "
      ],
      "metadata": {
        "id": "RFhuxjfqpkS5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ccd78f8b-f14d-48e1-f507-84da90a6df03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f84875d4450>]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = A<0.5*1"
      ],
      "metadata": {
        "id": "8WkrFTaSpkXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones_nn = (out*1==1)\n",
        "Y_nn = (Y==1)\n",
        "zeros_nn = (out*1==0)\n",
        "Y_nn = (Y==0)"
      ],
      "metadata": {
        "id": "4aURM6hEVr6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((Y_nn==zeros_nn).sum()*100/len(Y_nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhyVpam6WS-u",
        "outputId": "670cfa12-aca7-44bd-8419-93680330a386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.44976076555024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((Y_nn==ones_nn).sum()*100/len(Y_nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8uAAhFvXBt3",
        "outputId": "660a9df3-54e1-4e36-f458-3d7748c54ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65.55023923444976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "X = xtrain_\n",
        "y = np.array(train_label)\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=0.05,hidden_layer_sizes=(2, 2,3), random_state=1)\n",
        "\n",
        "clf.fit(X, y)\n",
        "#MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,solver='lbfgs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Efl9BgIXycz",
        "outputId": "16735e46-4846-4298-9a31-89a57bbd5f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=0.05, hidden_layer_sizes=(2, 2, 3), random_state=1,\n",
              "              solver='lbfgs')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(clf.score(X, y))*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEPqy0svaoyg",
        "outputId": "7c6a8e49-11dd-487e-dd5d-8ee3e0ae2bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.55023923444976"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}
