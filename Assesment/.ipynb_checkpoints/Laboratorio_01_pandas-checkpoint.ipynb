{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB0enqgBgefd"
   },
   "source": [
    "### <a href=\"https://colab.research.google.com/github/hernansalinas/Curso_aprendizaje_estadistico/blob/main/Assesment/Laboratorio_01_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzhBd58dWJXq"
   },
   "source": [
    "# Laboratorio 1.0 : Pandas:\n",
    "\n",
    "1. Manejo de datos con pandas:\n",
    "\n",
    "El siguiente [link](\n",
    "https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\n",
    "), contiene un DataSet con informacion que permite predecir si un cancer es benigno o maligno. Un detalle del dataset es dado a continuación:\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\n",
    "n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server:\n",
    "ftp ftp.cs.wisc.edu\n",
    "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1) ID number\n",
    "\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "\n",
    "c) perimeter\n",
    "\n",
    "d) area\n",
    "\n",
    "e) smoothness (local variation in radius lengths)\n",
    "\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "\n",
    "h) concave points (number of concave portions of the contour)\n",
    "\n",
    "i) symmetry\n",
    "\n",
    "j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three\n",
    "largest values) of these features were computed for each image,\n",
    "resulting in 30 features. For instance, field 3 is Mean Radius, field\n",
    "13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dg5T-MejYZf-"
   },
   "source": [
    "Para el dataset realizar lo siguiente:\n",
    "\n",
    "1. Leer los datos desde un archivo en el  git_hub.\n",
    "\n",
    "2. Renombrar las columnas en PascalCase\n",
    "  Ejemplo: La columna radius_worst, concave points_se deberia llamar: RadiusWorst, ConcavePointsSe\n",
    "\n",
    "3. Emplear los metodos head, tail, describe,info para obtener información acerca del dataframe,\n",
    "\n",
    "4. Contabilizar la cantidad de null or nan en el dataframe, replazar por el valor medio de cada columna.\n",
    "\n",
    "5. Encontrar los valores  diferentes en la columna Diagnosis, mostrar que es B y M. Emplear el metodo unique.\n",
    "\n",
    "6. Empleando la libreria seaborn y el metodo countplot, realice un conteo de las personas que tiene la etiqueta B y M.\n",
    "\n",
    "  ```python\n",
    "  import seaborn as sns\n",
    "  sns.countplot?\n",
    "  ```\n",
    "\n",
    "7. Agregar una nueva columna llamada DiagnosisNumeric, en la que cada valor B, M se corresponde con un valor 0, 1 respectivamente.\n",
    "\n",
    "8. Elimninar la columna id.\n",
    "\n",
    "9. Normalizar cada columna respecto a su media y desviación estandar: (x-mean(x))/std(x)\n",
    "\n",
    "10. En un mismo gráfico mostrar el histograma de la columna RadiusMean  para la etiqueta B y M en color naranja y azul de la columna Diagnosis respectivamente.\n",
    "\n",
    "11. Para las columnas:\n",
    "```python\n",
    "cols=['RadiusMean', 'TextureMean', 'PerimeterMean', 'AreaMean','SmoothnessMean', 'CompactnessMean', 'ConcavityMean','ConcavePointsMean']\n",
    "```\n",
    "realizar multiples histograma en un gráfico de [violin](https://seaborn.pydata.org/generated/seaborn.violinplot.html).\n",
    "\n",
    "```python\n",
    "data = pd.melt(df.iloc[:, 0:10], id_vars=\"Diagnosis\",var_name=\"features\",value_name=\"value\")\n",
    "sns.violinplot(x=\"features\",y=\"value\",  hue=\"Diagnosis\",data=data, split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=45)\n",
    "```\n",
    "\n",
    "10. Determinar los datos [outlier](https://en.wikipedia.org/wiki/Outlier)  para la columna RadiusMean y eliminarlos del data frame, para ello construya un gráfico tipo [boxplot](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html)\n",
    "\n",
    "```\n",
    "df.boxplot(column=\"RadiusMean\", by='Diagnosis', sym = 'k.', figsize=(18,6))\n",
    "```\n",
    "¿Qué informacion podemos obtener de este tipo de graficos?\n",
    "\n",
    "\n",
    "Usar el rango intercuartílico (IQR): El IQR es la diferencia entre el tercer y el primer cuartil de los datos, es decir, el 75% y el 25% de los valores ordenados. Los valores que están fuera del rango [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR] se consideran outliers y se pueden eliminar o reemplazar. Por ejemplo, si queremos eliminar los outliers de una columna llamada 'edad' usando el IQR, podemos hacer lo siguiente\n",
    "\n",
    "```python\n",
    "Q1 = df['edad'].quantile(0.25)\n",
    "Q3 = df['edad'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[~((df['edad'] < (Q1 - 1.5 * IQR)) | (df['edad'] > (Q3 + 1.5 * IQR)))]\n",
    "```\n",
    "\n",
    "Otra forma de determinar los outlier es con el puntaje Z:\n",
    "El puntaje Z es el número de desviaciones estándar que un valor está por encima o por debajo de la media. Los valores que tienen un puntaje Z mayor que un umbral (por ejemplo, 3) se consideran outliers y se pueden eliminar o reemplazar. Por ejemplo, si queremos eliminar los outliers de la columna 'edad' usando el puntaje Z, podemos hacer lo siguiente:\n",
    "\n",
    "```python\n",
    "df = df[(np.abs(stats.zscore(df['edad'])) < 3)]\n",
    "```\n",
    "\n",
    "En un problema de machine learning se debe elegir todas las columnas y construir un algoritmo que permite obtener la mejor calidad de los datos sobre todas las columnas.\n",
    "\n",
    "\n",
    "11. Encontrar la matrix de correlacion, emplear el metodo corr(), dentro de seaborn buscar el metodo heatmap() para realizar un grafico de la matrix de correlación.\n",
    "\n",
    "12. ¿Que otro tipo de gráficos pueden ser realizados para entender mejor los datos?\n",
    "\n",
    "\n",
    "\n",
    "# Laboratorio 1.1: Series de tiempo\n",
    "\n",
    "El siguiente [dataset](https://raw.githubusercontent.com/hernansalinas/Curso_aprendizaje_estadistico/main/datasets/Pandas_data_historical_dataEURUSD.csv) contiene información del precio del eur/usd  desde el 05/07/2022/ hasta el 12/05/2023 con periodicidad de una hora. El data frame contiene el precio de apertura, cierrre, valor más bajo cotizado, valor más alto cotizado, volumen, spread etc. Para este dataset, realizar lo siguiente:\n",
    "\n",
    "\n",
    "1. Leer el dataset desde el github.\n",
    "2. Definir como indice la columna time.\n",
    "3. Obtenga información del data frame.\n",
    "\n",
    "4. Determine si hay null, nan en el data frame.\n",
    "\n",
    "5. Emplea la notacion Pascal Case y trabaja solo con la columa del precio de cierre del eur/usd.  \n",
    "\n",
    "6. Ahora vamos a determinar cual es la mejor distribución estadística que se ajusta a la diferencia del precio de cierre cada hora, para ello realizamos lo siguiente:\n",
    "- Determine la diferencia de precio entre horas, agregue una nueva columna llamada DiffPrice, en este punto tu dataframe debe tener solo dos columnas Close, DiffPrice y el indice debe ser el tiempo.\n",
    "- Para la nueva columna construya un histograma de los datos.\n",
    "- Determine la mejor distribucion estadística que se ajusta al histograma anterior, para ello puede emplear lo siguente:\n",
    "\n",
    "\n",
    "```python\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "\n",
    "f = Fitter(data,\n",
    "           distributions=['gamma',\n",
    "                          'lognorm',\n",
    "                          \"beta\",\n",
    "                          \"burr\",\n",
    "                          \"norm\"])\n",
    "f.fit()\n",
    "f.summary()\n",
    "#Indentificamos la mejor distribucion con el error cuadratico medio\n",
    "f.get_best(method = 'sumsquare_error')\n",
    "#Indentificamos parametros de la distrubicion beta\n",
    "f.fitted_param[\"beta\"]\n",
    "\n",
    "```\n",
    "\n",
    "Con el metodo get_distributions(), podemos ver todas las distribuciones estadisticas de la libreria. Ajusta a la mejor.  Puede consultar [esta](https://medium.com/the-researchers-guide/finding-the-best-distribution-that-fits-your-data-using-pythons-fitter-library-319a5a0972e9)  página si desea ver un ejemplo.\n",
    "\n",
    "\n",
    "5. Para el data frame, seleccionemos solo los. datos del 2023.\n",
    "\n",
    "5. El comando groupby permite agrupar los datos con la periodicidad deseada: 1 dias, 2 dias, 1 mes etc. Determina el promedio con una periodicidad de 15 dias, con periodidicidad de 1 semana, y una periodicidad de 1 mes\n",
    "\n",
    "```python\n",
    "  df.groupby(pd.Grouper(key='time', freq='15D')).mean()\n",
    "```\n",
    "\n",
    "6. Para los datos asociados a los meses de 2023, construya un histograma para cada mes.  Para ello puedo emplear el metodo groupby. Notetese que si no  realiza una operación después de aplicar el metodo grouby, podrias iterar sobre dicho objeto, por ejemplo:\n",
    "\n",
    "```python\n",
    "q=df.groupby(pd.Grouper(key='time', freq='15D'))\n",
    "\n",
    "for name, group in q:\n",
    "  print(name, group)\n",
    "```\n",
    "\n",
    "\n",
    "Realiza gráfico análogo a esta (referencia)[https://seaborn.pydata.org/examples/kde_ridgeplot.html]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!--\n",
    "En este [link](http://berkeleyearth.lbl.gov/auto/Global/Land_and_Ocean_complete.txt) se encuentra un\n",
    "  data set que tiene información de la temperatura de la tierra desde 1850. Descripción de cada unas de las variables e información es detallada en el interior del archivo.\n",
    "\n",
    "\n",
    "1. Leer el archivo de datos\n",
    "2. Construir un dataframe con las columnas:\n",
    "\n",
    "```\n",
    "columns = [\"Year\",\"Month\",\"MonthlyA\",\"MonthlyUnc\",\"AnnuealA\",\"AnnuealUnc\",\\\n",
    "           \"FiveA\",\"AnnuealUnc\",\"TenA\",\"AnnuealUnc\",\"TwentyA\",\"AnnuealUnc\"]\n",
    "```\n",
    "3. Construir una nueva columna tipo string llamada Date con la informacion del Year y Month\n",
    "\n",
    "4. Emplear el commando [datetime](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) para dar el formato tipo date  a la nueva columna Date.\n",
    "  \n",
    "  ```\n",
    "  df[\"Date\"] = pd.to_datetime(df[\"Date\"],format='%Y%m')\n",
    "  ```\n",
    "5. Emplear el metodo groupby and grouper para tomar los datos con un periodicidad mensual. Notese que freq permite variar la periodicidad con la que se quieren mostrar los datos. Pruebe para freq=\"2M\", \"3M\", \"Y\", \"H\".\n",
    "\n",
    "  ```\n",
    "  T_serie = df.groupby(pd.Grouper(key='date', freq='M')).mean()\n",
    "  ```\n",
    "\n",
    "\n",
    "6. Realice un gráfico del tiempo como función de  MonthlyA.\n",
    "\n",
    "7. ¿Que puede concluir? -->\n",
    "\n",
    "\n",
    "Referencias\n",
    "\n",
    "- [It’s Not Your Imagination. Summers Are Getting Hotter](https://www.nytimes.com/interactive/2021/climate/extreme-summer-heat.html)\n",
    "\n",
    "- http://berkeleyearth.org/data/\n",
    "\n",
    "- http://berkeleyearth.lbl.gov/auto/Global/Land_and_Ocean_complete.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyhIUpJmfXQr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
