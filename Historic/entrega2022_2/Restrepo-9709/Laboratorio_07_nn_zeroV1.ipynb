{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pRgo1ME0pauT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6GPOdoLjBAC"
   },
   "source": [
    "Construyamos una red neuronal con una capa de entrada, una capa de salida con una red y L-1 redes ocultas.\n",
    "\n",
    "# Con m datos de entrenamientos.\n",
    "\n",
    "Para $m$ datos de entrenamiento, las expresión anteriores pueden ser resumidas en las siguientes ecuaciones\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "z_1^{(0)}  &z_1^{(1)} & .&.& .&z_1^{(m)}\\\\\n",
    "z_2^{(0)}  &z_2^{(1)} &. &.&  .&z_2^{(m)}\\\\\n",
    ".          & .        &. & &   &.      \\\\\n",
    ".          & .        &  &. &   &.      \\\\\n",
    ".          & .        &  &  & .&      \\\\\n",
    "z_{n^{[l]}}^{(0)}&z_{n^{[l]}}^{(1)} & . & .& .& z_{n^{[l]}}^{(m)}        \\\\\n",
    "\\end{bmatrix}^{[l]}=\n",
    "\\begin{bmatrix}\n",
    "\\theta_{11} & \\theta_{12} & . & .& .& \\theta_{1n^{[l-1]}}\\\\\n",
    "\\theta_{21} & \\theta_{22} & . & .& .& \\theta_{2n^{[l-1]}}\\\\\n",
    ". & .  & . &   & & .\\\\\n",
    ". & .  &   & . & & .\\\\\n",
    ". & .  &   &  & .& .\\\\\n",
    "\\theta_{n^{[l]}1} & \\theta_{n^{[l]}2} & . & .& .& \\theta_{n^{[l]}n^{[l-1]}}\\\\\n",
    "\\end{bmatrix}^{[l]}_{n^{[l]} \\times n^{[l-1]}}\n",
    "\\begin{bmatrix}\n",
    "a_1^{(0)}  &a_1^{(1)} & .&.& .&a_1^{(m)}\\\\\n",
    "a_2^{(0)}  &a_2^{(1)} &. &.&  .&a_2^{(m)}\\\\\n",
    ".          & .        &. & &   &.      \\\\\n",
    ".          & .        &  &. &   &.      \\\\\n",
    ".          & .        &  &  & .&      \\\\\n",
    "a_{n^{[L-1]}}^{(0)}&a_{n^{[L-1]}}^{(1)} & . & .& .& a_{n^{[L-1]}}^{(m)}        \\\\\n",
    "\\end{bmatrix}^{[l-1]} +\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "b_{n^{[l]}}\\\\\n",
    "\\end{bmatrix}^{[l]} \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Escrito de una formas mas compacta tenemos que:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "[ \\vec{Z}^{[l](0)},\\vec{Z}^{[l](1)},...,\\vec{Z}^{[l](m)}  ]= \\Theta^{[l]} [\\vec{A}^{[l-1](0)},\\vec{A}^{[l-1](1)},...,\\vec{A}^{[l-1](m)} ]+ \\vec{b}^{[l]}\n",
    "\\end{equation}\n",
    "\n",
    "Aplicando la funcion de activación:\n",
    "\n",
    "\\begin{equation}\n",
    "[\\vec{A}^{[l](0)},\\vec{A}^{[l](1)},...,\\vec{A}^{[l](m)} ]=f([\\vec{Z}^{[l](0)},\\vec{Z}^{[l](1)},...,\\vec{Z}^{[l](m)}  ]) \n",
    "\\end{equation}\n",
    "\n",
    "Las dimensiones de las expresiones anteriores, pueden ser resumidas en lo siguiente:\n",
    "\n",
    "$\\mathrm{dim(\\vec{\\cal{Z}}^{[l]})}=n^{[l]}\\times m $\n",
    "\n",
    "$\\mathrm{dim(\\vec{\\Theta}^{[l]})}=n^{[l]}\\times n^{[l-1]}$\n",
    "\n",
    "$\\mathrm{dim(\\vec{\\cal{A}}^{[l]})}=n^{[l-1]}\\times m $\n",
    "\n",
    "$\\mathrm{dim(\\vec{b}^{[l]})}=n^{[l]}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPCHleHyjGL5"
   },
   "source": [
    "## Topologia de la red.\n",
    "\n",
    "1. Construir un algorítmo que permita definir una red neuronal con la topología\n",
    "deseada y la función de activación para cada capa:\n",
    "\n",
    "Topology = [n_x, n_h1, n_h2, n_h3, ...,n_y]\n",
    "\n",
    "activation=[None, relu, relu, relu, ...,sigmoid]\n",
    "\n",
    "  - $\\mathrm{n_x}$: valores de entrada\n",
    "  - $\\mathrm{n_{h1}}$: hidden layer 1 \n",
    "  - $\\mathrm{n_{h2}}$: hidden layer 2\n",
    "  - $\\mathrm{n_y}$: last layer \n",
    "\n",
    "\n",
    "\n",
    "Se sugiere para cada capa emplear programación orientada a objetos definida de la siguiente manera:\n",
    "\n",
    "```\n",
    "class layer_nn():\n",
    "  def __init__(self, act_fun, nlayer_present, nlayer_before):\n",
    "    self.theta = 2*np.random.random((nlayer_present, nlayer_before)) - 1\n",
    "    self.B = 2*np.random.random((nlayer_present,1)) - 1\n",
    "    self.act_fun = act_fun\n",
    "\n",
    "  def output(self, Z, A):\n",
    "    self.Z = Z\n",
    "    self.A = A\n",
    "\n",
    "\n",
    "\n",
    "def act_function(x, activation):\n",
    "  if activation==\"sigmoid\":\n",
    "    f = lambda x: 1/(1+np.exp(-x))\n",
    "    fp = f(x)*(1-f(x))\n",
    "    return f, fp\n",
    "  \n",
    "  elif activation == \"tanh\":\n",
    "    f = lambda x: np.tanh\n",
    "    return tanh\n",
    "  else :\n",
    "    return 0\n",
    "```\n",
    "    \n",
    "\n",
    "2. Construir un generalizacion de la red, en el que entrada el valor inicial \n",
    "y la red neuronal completa arroje la salida y la actualizacion de la red con los parametros deseados:\n",
    "\n",
    "  ```\n",
    "  A, nn = forward_pass(A0, nn_red)\n",
    "\n",
    " ```\n",
    "3. Encontrar la funcion de coste.\n",
    "\n",
    "\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right)) \\tag{7}$$\n",
    "\n",
    "\n",
    "4. Construir un codigo que permita realizar el BackwardPropagation \n",
    "\n",
    "\n",
    "# Backward Propagation\n",
    "\n",
    "Para una capa $l$ arbitraria tenemos que:\n",
    "\n",
    "- \\begin{equation}\n",
    "d\\Theta^{[l]} =  d{\\cal Z}^{(i)[l]} Trans(A)^{(i)[l-1]} = dA^{(i)[l]} f'({\\cal Z}^{(i)[l]} ) Trans(A)^{(i)[l-1]}\n",
    "\\end{equation}\n",
    "\n",
    "- \\begin{equation}\n",
    "db^{[l]} =  d{\\cal Z}^{(i)[L]}  = dA^{(i)[l]} f'({\\cal Z}^{(i)[l]} ) \n",
    "\\end{equation}\n",
    "```\n",
    "db_L =  m_*np.sum(dZ, axis=1, keepdims=True)\n",
    "```\n",
    "Los valores de dA pueden ser escritos como:\n",
    "- \\begin{equation}\n",
    "dA^{(i)[l-1]} = \\Theta^{l} \\cdot dZ^{(i)[l]}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$ dZ^{[l]} = dA^{[l]} * f'^{[l]} (Z^{[l]}) $\n",
    "$ d\\Theta^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial \\Theta^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T} \\tag{1}$\n",
    "$ db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}\\tag{2}$\n",
    "$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = \\theta^{[l] T} dZ^{[l]} \\tag{3}$\n",
    "\n",
    "\n",
    "Para la capa L esima: \n",
    "\n",
    "```\n",
    "dAL = -(np.divide(Y, A) - np.divide(1 - Y, 1 - A))\n",
    "```\n",
    "\n",
    "# Aplicacion gradiente descendente\n",
    "\n",
    "$$ \\Theta^{[l]} = \\Theta^{[l]} - \\alpha \\text{ } d\\Theta^{[l]} \\tag{16}$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} \\tag{17}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "onnQT24Upcx1"
   },
   "outputs": [],
   "source": [
    "class layer_nn():\n",
    "  \"\"\"\n",
    "  Definición de la capas de la red neuronal \n",
    "  e inicializacion de parametros. \n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,act_fun, n_layer_present, n_layer_before ):    \n",
    "    self.W = 2*np.random.random((n_layer_before,n_layer_present)) - 1\n",
    "    self.B = 2*np.random.random((n_layer_present,1)) - 1\n",
    "    self.act_fun = act_fun\n",
    "\n",
    "  def output(self, Z,A, Ap):\n",
    "    self.Z = Z\n",
    "    self.A = A\n",
    "    self.Ap = Ap\n",
    "\n",
    "  def derivates(self, dW, db):\n",
    "    self.dW = dW\n",
    "    self.db = db\n",
    "\n",
    "@np.vectorize\n",
    "def relu(x):\n",
    "  if(x>=0):\n",
    "    return x\n",
    "  else :\n",
    "    return 0\n",
    "\n",
    "@np.vectorize\n",
    "def reluP(x):\n",
    "  if(x>=0):\n",
    "    return 1\n",
    "  else :\n",
    "    return 0\n",
    "\n",
    "def sigmoide(x):      \n",
    "  f= lambda x: 1/(1+np.exp(-x))\n",
    "  return f(x)\n",
    "\n",
    "def act_function(x, activation):        \n",
    "    if activation == \"sigmoid\":\n",
    "        f = sigmoide(x)\n",
    "        fp = sigmoide(x)*(1-sigmoide(x))\n",
    "    elif activation == \"tanh\":\n",
    "        f = lambda x: np.tanh(x)\n",
    "\n",
    "    elif activation == \"relu\":\n",
    "        f = relu(x)\n",
    "        fp = reluP(x)\n",
    "    \n",
    "    return f, fp\n",
    "    \n",
    "\n",
    "def forward_pass(input, nn_red):\n",
    "  A0 = input  \n",
    "  nn_red_update = []\n",
    "  \n",
    "  for layer in nn_red: \n",
    "    Z = layer.W.T@A0 + layer.B    \n",
    "    A, Ap = act_function(Z, layer.act_fun)        \n",
    "    layer.output(Z, A, Ap)    \n",
    "    nn_red_update.append(layer)\n",
    "    A0 = A        \n",
    "  return A, nn_red_update\n",
    "\n",
    "\n",
    "def cost_Function(A, Y):\n",
    "  m = Y.shape[0]\n",
    "  m_ = 1/m\n",
    "  cost = Y*np.log(A)+(1-Y)*np.log(1-A)\n",
    "  cost = -m_*cost.sum()\n",
    "  return cost\n",
    "\n",
    "def backward_propagation(AL,Y,nn):\n",
    "  L = len(nn) - 1\n",
    "  \n",
    "  dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "  fp = nn[L].Ap \n",
    "  dZ = dAL*fp  \n",
    "  m_ = 1/np.shape(Y)[0]\n",
    "\n",
    "  dW_L = m_*dZ@nn[L-1].Ap.T\n",
    "  db_L = m_*np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "  nn[L].dW=dW_L\n",
    "  nn[L].db=db_L\n",
    "\n",
    "  dAL_1 = np.dot(nn[L].W, dZ)\n",
    "\n",
    "  for l in reversed(range(1,L)):\n",
    "#    dAL_1 = dAL \n",
    "    fp = nn[l].Ap\n",
    "    dZ_1 = dAL_1*fp\n",
    "    dW_L1 = m_*dZ_1@nn[l-1].Ap.T\n",
    "    db_L1 = m_*np.sum(dZ_1, axis=1, keepdims=True)\n",
    "    \n",
    "   # dAL = dAL_1.copy()\n",
    "    \n",
    "    nn[l].dW=dW_L1\n",
    "    nn[l].db=db_L1\n",
    "    dAL_1 = np.dot(nn[l].W,dZ_1)\n",
    "  return nn\n",
    "\n",
    "\n",
    "def update_params(nn, learning_rate):  \n",
    "  L=len(nn)\n",
    "  for l in range(1, L):    \n",
    "    nn[l].W = nn[l].W - learning_rate*nn[l].dW.T  \n",
    "    nn[l].B = nn[l].B - learning_rate*nn[l].db\n",
    "  return nn\n",
    "\n",
    "def red_neuronal(topology, act_fn):\n",
    "  nn_red = []\n",
    "  L = len(topology)\n",
    "  for i in range(1, L):  \n",
    "    nn_red.append(layer_nn(act_fn[i],topology[i],topology[i-1] ) )  \n",
    "  return nn_red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "q1zzHdlSpeRV"
   },
   "outputs": [],
   "source": [
    "n_x = 12288# -- size of the input layer\n",
    "#n_h = # -- size of the hidden layer\n",
    "n_y = 1# -- size of the output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ySGq43G4pe0p"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data_train= \"Curso_aprendizaje_estadistico/Assesment/dataset/train_catvnoncat.h5\"\n",
    "train_dataset = h5py.File(data_train, \"r\")\n",
    " \n",
    "data_test= \"Curso_aprendizaje_estadistico/Assesment/dataset/test_catvnoncat.h5\"\n",
    "test_dataset = h5py.File(data_test, \"r\")\n",
    "\n",
    "xtrain_classes, xtrain, train_label =\\\n",
    "train_dataset[\"list_classes\"],train_dataset[\"train_set_x\"],train_dataset[\"train_set_y\"]\n",
    "\n",
    "test_classes, xtest,test_label =\\\n",
    "test_dataset[\"list_classes\"],test_dataset[\"test_set_x\"],test_dataset[\"test_set_y\"]\n",
    "\n",
    "xtrain_= np.reshape(xtrain,(209, 64*64*3))/255\n",
    "xtest_ = np.reshape(xtest,(50, 64*64*3))/255\n",
    "\n",
    "topology = [n_x,2,2,3,1]\n",
    "act_fn   = [None,\"relu\", \"relu\", \"relu\",\"sigmoid\" ]\n",
    "\n",
    "nn_red = red_neuronal(topology, act_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "RFhuxjfqpkS5",
    "outputId": "ccd78f8b-f14d-48e1-f507-84da90a6df03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc115381518>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Aini = xtrain_.T\n",
    "Y = np.array(train_label)\n",
    "A, nn = forward_pass(Aini, nn_red)\n",
    "\n",
    "Max_iter = 500\n",
    "J = np.zeros(Max_iter)\n",
    "J[0] = cost_Function(A, np.array(train_label))\n",
    "\n",
    "for i in range(1,Max_iter):\n",
    "  nn = backward_propagation(A, Y, nn)\n",
    "  nn = update_params(nn, 0.005)  \n",
    "  A, nn = forward_pass(Aini, nn)\n",
    "  J[i] = cost_Function(A, np.array(train_label))\n",
    "\n",
    "plt.plot(J,\"ro-\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8WkrFTaSpkXS"
   },
   "outputs": [],
   "source": [
    "out = A<0.5*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4aURM6hEVr6c"
   },
   "outputs": [],
   "source": [
    "ones_nn = (out*1==1)\n",
    "Y_nn = (Y==1)\n",
    "zeros_nn = (out*1==0)\n",
    "Y_nn = (Y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhyVpam6WS-u",
    "outputId": "670cfa12-aca7-44bd-8419-93680330a386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.44976076555024\n"
     ]
    }
   ],
   "source": [
    "print((Y_nn==zeros_nn).sum()*100/len(Y_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8uAAhFvXBt3",
    "outputId": "660a9df3-54e1-4e36-f458-3d7748c54ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.55023923444976\n"
     ]
    }
   ],
   "source": [
    "print((Y_nn==ones_nn).sum()*100/len(Y_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN usando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Efl9BgIXycz",
    "outputId": "16735e46-4846-4298-9a31-89a57bbd5f88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=3, hidden_layer_sizes=(3, 5, 5), learning_rate_init=0.5,\n",
       "              max_iter=2000, random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = xtrain_\n",
    "y = np.array(train_label)\n",
    "clf = MLPClassifier(solver='lbfgs', learning_rate_init = 0.5, alpha = 3, hidden_layer_sizes=(3,5,5),max_iter = 2000, random_state=1)\n",
    "\n",
    "clf.fit(X, y)\n",
    "#MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEPqy0svaoyg",
    "outputId": "7c6a8e49-11dd-487e-dd5d-8ee3e0ae2bb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.04306220095694"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clf.score(X, y))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(xtest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(xtest_,test_label)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.75561602e-02, 9.62443840e-01],\n",
       "       [1.59275757e-01, 8.40724243e-01],\n",
       "       [2.03329550e-01, 7.96670450e-01],\n",
       "       [6.23140357e-01, 3.76859643e-01],\n",
       "       [6.88328641e-01, 3.11671359e-01],\n",
       "       [2.23263573e-01, 7.76736427e-01],\n",
       "       [9.99627054e-01, 3.72945833e-04],\n",
       "       [2.92946810e-01, 7.07053190e-01],\n",
       "       [3.75624705e-02, 9.62437530e-01],\n",
       "       [1.00830568e-01, 8.99169432e-01],\n",
       "       [7.06749510e-01, 2.93250490e-01],\n",
       "       [2.97594280e-01, 7.02405720e-01],\n",
       "       [7.29198338e-02, 9.27080166e-01],\n",
       "       [8.55435066e-01, 1.44564934e-01],\n",
       "       [9.99955642e-01, 4.43584243e-05],\n",
       "       [1.49342317e-01, 8.50657683e-01],\n",
       "       [9.84364788e-01, 1.56352122e-02],\n",
       "       [3.75710726e-02, 9.62428927e-01],\n",
       "       [9.96413695e-01, 3.58630527e-03],\n",
       "       [9.99971167e-01, 2.88333271e-05],\n",
       "       [4.08168453e-02, 9.59183155e-01],\n",
       "       [8.79211146e-01, 1.20788854e-01],\n",
       "       [9.98981116e-01, 1.01888399e-03],\n",
       "       [6.37584011e-02, 9.36241599e-01],\n",
       "       [1.34580548e-01, 8.65419452e-01],\n",
       "       [2.38329614e-01, 7.61670386e-01],\n",
       "       [9.96317404e-01, 3.68259646e-03],\n",
       "       [9.99139829e-01, 8.60170544e-04],\n",
       "       [9.51934754e-01, 4.80652456e-02],\n",
       "       [5.55318545e-02, 9.44468146e-01],\n",
       "       [8.68927055e-01, 1.31072945e-01],\n",
       "       [1.63265633e-01, 8.36734367e-01],\n",
       "       [2.50830077e-01, 7.49169923e-01],\n",
       "       [2.21578789e-01, 7.78421211e-01],\n",
       "       [5.76730450e-02, 9.42326955e-01],\n",
       "       [9.75118654e-01, 2.48813461e-02],\n",
       "       [9.71955908e-01, 2.80440921e-02],\n",
       "       [4.03271648e-01, 5.96728352e-01],\n",
       "       [8.95920357e-01, 1.04079643e-01],\n",
       "       [9.87350476e-01, 1.26495239e-02],\n",
       "       [3.43167455e-01, 6.56832545e-01],\n",
       "       [9.99882712e-01, 1.17288195e-04],\n",
       "       [1.00100281e-01, 8.99899719e-01],\n",
       "       [9.94091535e-01, 5.90846515e-03],\n",
       "       [3.75561602e-02, 9.62443840e-01],\n",
       "       [8.85031561e-01, 1.14968439e-01],\n",
       "       [8.14654475e-01, 1.85345525e-01],\n",
       "       [3.75561602e-02, 9.62443840e-01],\n",
       "       [3.75648974e-02, 9.62435103e-01],\n",
       "       [9.28756375e-01, 7.12436250e-02]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(xtest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sesion_10_nn_routines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
