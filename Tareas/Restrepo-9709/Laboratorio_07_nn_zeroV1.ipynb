{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "pRgo1ME0pauT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6GPOdoLjBAC"
   },
   "source": [
    "Construyamos una red neuronal con una capa de entrada, una capa de salida con una red y L-1 redes ocultas.\n",
    "\n",
    "# Con m datos de entrenamientos.\n",
    "\n",
    "Para $m$ datos de entrenamiento, las expresión anteriores pueden ser resumidas en las siguientes ecuaciones\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "z_1^{(0)}  &z_1^{(1)} & .&.& .&z_1^{(m)}\\\\\n",
    "z_2^{(0)}  &z_2^{(1)} &. &.&  .&z_2^{(m)}\\\\\n",
    ".          & .        &. & &   &.      \\\\\n",
    ".          & .        &  &. &   &.      \\\\\n",
    ".          & .        &  &  & .&      \\\\\n",
    "z_{n^{[l]}}^{(0)}&z_{n^{[l]}}^{(1)} & . & .& .& z_{n^{[l]}}^{(m)}        \\\\\n",
    "\\end{bmatrix}^{[l]}=\n",
    "\\begin{bmatrix}\n",
    "\\theta_{11} & \\theta_{12} & . & .& .& \\theta_{1n^{[l-1]}}\\\\\n",
    "\\theta_{21} & \\theta_{22} & . & .& .& \\theta_{2n^{[l-1]}}\\\\\n",
    ". & .  & . &   & & .\\\\\n",
    ". & .  &   & . & & .\\\\\n",
    ". & .  &   &  & .& .\\\\\n",
    "\\theta_{n^{[l]}1} & \\theta_{n^{[l]}2} & . & .& .& \\theta_{n^{[l]}n^{[l-1]}}\\\\\n",
    "\\end{bmatrix}^{[l]}_{n^{[l]} \\times n^{[l-1]}}\n",
    "\\begin{bmatrix}\n",
    "a_1^{(0)}  &a_1^{(1)} & .&.& .&a_1^{(m)}\\\\\n",
    "a_2^{(0)}  &a_2^{(1)} &. &.&  .&a_2^{(m)}\\\\\n",
    ".          & .        &. & &   &.      \\\\\n",
    ".          & .        &  &. &   &.      \\\\\n",
    ".          & .        &  &  & .&      \\\\\n",
    "a_{n^{[L-1]}}^{(0)}&a_{n^{[L-1]}}^{(1)} & . & .& .& a_{n^{[L-1]}}^{(m)}        \\\\\n",
    "\\end{bmatrix}^{[l-1]} +\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "b_{n^{[l]}}\\\\\n",
    "\\end{bmatrix}^{[l]} \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Escrito de una formas mas compacta tenemos que:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "[ \\vec{Z}^{[l](0)},\\vec{Z}^{[l](1)},...,\\vec{Z}^{[l](m)}  ]= \\Theta^{[l]} [\\vec{A}^{[l-1](0)},\\vec{A}^{[l-1](1)},...,\\vec{A}^{[l-1](m)} ]+ \\vec{b}^{[l]}\n",
    "\\end{equation}\n",
    "\n",
    "Aplicando la funcion de activación:\n",
    "\n",
    "\\begin{equation}\n",
    "[\\vec{A}^{[l](0)},\\vec{A}^{[l](1)},...,\\vec{A}^{[l](m)} ]=f([\\vec{Z}^{[l](0)},\\vec{Z}^{[l](1)},...,\\vec{Z}^{[l](m)}  ]) \n",
    "\\end{equation}\n",
    "\n",
    "Las dimensiones de las expresiones anteriores, pueden ser resumidas en lo siguiente:\n",
    "\n",
    "$\\mathrm{dim(\\vec{\\cal{Z}}^{[l]})}=n^{[l]}\\times m $\n",
    "\n",
    "$\\mathrm{dim(\\vec{\\Theta}^{[l]})}=n^{[l]}\\times n^{[l-1]}$\n",
    "\n",
    "$\\mathrm{dim(\\vec{\\cal{A}}^{[l]})}=n^{[l-1]}\\times m $\n",
    "\n",
    "$\\mathrm{dim(\\vec{b}^{[l]})}=n^{[l]}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPCHleHyjGL5"
   },
   "source": [
    "## Topologia de la red.\n",
    "\n",
    "1. Construir un algorítmo que permita definir una red neuronal con la topología\n",
    "deseada y la función de activación para cada capa:\n",
    "\n",
    "Topology = [n_x, n_h1, n_h2, n_h3, ...,n_y]\n",
    "\n",
    "activation=[None, relu, relu, relu, ...,sigmoid]\n",
    "\n",
    "  - $\\mathrm{n_x}$: valores de entrada\n",
    "  - $\\mathrm{n_{h1}}$: hidden layer 1 \n",
    "  - $\\mathrm{n_{h2}}$: hidden layer 2\n",
    "  - $\\mathrm{n_y}$: last layer \n",
    "\n",
    "\n",
    "\n",
    "Se sugiere para cada capa emplear programación orientada a objetos definida de la siguiente manera:\n",
    "\n",
    "```\n",
    "class layer_nn():\n",
    "  def __init__(self, act_fun, nlayer_present, nlayer_before):\n",
    "    self.theta = 2*np.random.random((nlayer_present, nlayer_before)) - 1\n",
    "    self.B = 2*np.random.random((nlayer_present,1)) - 1\n",
    "    self.act_fun = act_fun\n",
    "\n",
    "  def output(self, Z, A):\n",
    "    self.Z = Z\n",
    "    self.A = A\n",
    "\n",
    "\n",
    "\n",
    "def act_function(x, activation):\n",
    "  if activation==\"sigmoid\":\n",
    "    f = lambda x: 1/(1+np.exp(-x))\n",
    "    fp = f(x)*(1-f(x))\n",
    "    return f, fp\n",
    "  \n",
    "  elif activation == \"tanh\":\n",
    "    f = lambda x: np.tanh\n",
    "    return tanh\n",
    "  else :\n",
    "    return 0\n",
    "```\n",
    "    \n",
    "\n",
    "2. Construir un generalizacion de la red, en el que entrada el valor inicial \n",
    "y la red neuronal completa arroje la salida y la actualizacion de la red con los parametros deseados:\n",
    "\n",
    "  ```\n",
    "  A, nn = forward_pass(A0, nn_red)\n",
    "\n",
    " ```\n",
    "3. Encontrar la funcion de coste.\n",
    "\n",
    "\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right)) \\tag{7}$$\n",
    "\n",
    "\n",
    "4. Construir un codigo que permita realizar el BackwardPropagation \n",
    "\n",
    "\n",
    "# Backward Propagation\n",
    "\n",
    "Para una capa $l$ arbitraria tenemos que:\n",
    "\n",
    "- \\begin{equation}\n",
    "d\\Theta^{[l]} =  d{\\cal Z}^{(i)[l]} Trans(A)^{(i)[l-1]} = dA^{(i)[l]} f'({\\cal Z}^{(i)[l]} ) Trans(A)^{(i)[l-1]}\n",
    "\\end{equation}\n",
    "\n",
    "- \\begin{equation}\n",
    "db^{[l]} =  d{\\cal Z}^{(i)[L]}  = dA^{(i)[l]} f'({\\cal Z}^{(i)[l]} ) \n",
    "\\end{equation}\n",
    "```\n",
    "db_L =  m_*np.sum(dZ, axis=1, keepdims=True)\n",
    "```\n",
    "Los valores de dA pueden ser escritos como:\n",
    "- \\begin{equation}\n",
    "dA^{(i)[l-1]} = \\Theta^{l} \\cdot dZ^{(i)[l]}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$ dZ^{[l]} = dA^{[l]} * f'^{[l]} (Z^{[l]}) $\n",
    "$ d\\Theta^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial \\Theta^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T} \\tag{1}$\n",
    "$ db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}\\tag{2}$\n",
    "$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = \\theta^{[l] T} dZ^{[l]} \\tag{3}$\n",
    "\n",
    "\n",
    "Para la capa L esima: \n",
    "\n",
    "```\n",
    "dAL = -(np.divide(Y, A) - np.divide(1 - Y, 1 - A))\n",
    "```\n",
    "\n",
    "# Aplicacion gradiente descendente\n",
    "\n",
    "$$ \\Theta^{[l]} = \\Theta^{[l]} - \\alpha \\text{ } d\\Theta^{[l]} \\tag{16}$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} \\tag{17}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "onnQT24Upcx1"
   },
   "outputs": [],
   "source": [
    "class layer_nn():\n",
    "  \"\"\"\n",
    "  Definición de la capas de la red neuronal \n",
    "  e inicializacion de parametros. \n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,act_fun, n_layer_present, n_layer_before ):    \n",
    "    self.W = 2*np.random.random((n_layer_before,n_layer_present)) - 1\n",
    "    self.B = 2*np.random.random((n_layer_present,1)) - 1\n",
    "    self.act_fun = act_fun\n",
    "\n",
    "  def output(self, Z,A, Ap):\n",
    "    self.Z = Z\n",
    "    self.A = A\n",
    "    self.Ap = Ap\n",
    "\n",
    "  def derivates(self, dW, db):\n",
    "    self.dW = dW\n",
    "    self.db = db\n",
    "\n",
    "@np.vectorize\n",
    "def relu(x):\n",
    "  if(x>=0):\n",
    "    return x\n",
    "  else :\n",
    "    return 0\n",
    "\n",
    "@np.vectorize\n",
    "def reluP(x):\n",
    "  if(x>=0):\n",
    "    return 1\n",
    "  else :\n",
    "    return 0\n",
    "\n",
    "def sigmoide(x):      \n",
    "  f= lambda x: 1/(1+np.exp(-x))\n",
    "  return f(x)\n",
    "\n",
    "def act_function(x, activation):        \n",
    "    if activation == \"sigmoid\":\n",
    "        f = sigmoide(x)\n",
    "        fp = sigmoide(x)*(1-sigmoide(x))\n",
    "    elif activation == \"tanh\":\n",
    "        f = lambda x: np.tanh(x)\n",
    "\n",
    "    elif activation == \"relu\":\n",
    "        f = relu(x)\n",
    "        fp = reluP(x)\n",
    "    \n",
    "    return f, fp\n",
    "    \n",
    "\n",
    "def forward_pass(input, nn_red):\n",
    "  A0 = input  \n",
    "  nn_red_update = []\n",
    "  \n",
    "  for layer in nn_red: \n",
    "    Z = layer.W.T@A0 + layer.B    \n",
    "    A, Ap = act_function(Z, layer.act_fun)        \n",
    "    layer.output(Z, A, Ap)    \n",
    "    nn_red_update.append(layer)\n",
    "    A0 = A        \n",
    "  return A, nn_red_update\n",
    "\n",
    "\n",
    "def cost_Function(A, Y):\n",
    "  m = Y.shape[0]\n",
    "  m_ = 1/m\n",
    "  cost = Y*np.log(A)+(1-Y)*np.log(1-A)\n",
    "  cost = -m_*cost.sum()\n",
    "  return cost\n",
    "\n",
    "def backward_propagation(AL,Y,nn):\n",
    "  L = len(nn) - 1\n",
    "  \n",
    "  dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "  fp = nn[L].Ap \n",
    "  dZ = dAL*fp  \n",
    "  m_ = 1/np.shape(Y)[0]\n",
    "\n",
    "  dW_L = m_*dZ@nn[L-1].Ap.T\n",
    "  db_L = m_*np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "  nn[L].dW=dW_L\n",
    "  nn[L].db=db_L\n",
    "\n",
    "  dAL_1 = np.dot(nn[L].W, dZ)\n",
    "\n",
    "  for l in reversed(range(1,L)):\n",
    "#    dAL_1 = dAL \n",
    "    fp = nn[l].Ap\n",
    "    dZ_1 = dAL_1*fp\n",
    "    dW_L1 = m_*dZ_1@nn[l-1].Ap.T\n",
    "    db_L1 = m_*np.sum(dZ_1, axis=1, keepdims=True)\n",
    "    \n",
    "   # dAL = dAL_1.copy()\n",
    "    \n",
    "    nn[l].dW=dW_L1\n",
    "    nn[l].db=db_L1\n",
    "    dAL_1 = np.dot(nn[l].W,dZ_1)\n",
    "  return nn\n",
    "\n",
    "\n",
    "def update_params(nn, learning_rate):  \n",
    "  L=len(nn)\n",
    "  for l in range(1, L):    \n",
    "    nn[l].W = nn[l].W - learning_rate*nn[l].dW.T  \n",
    "    nn[l].B = nn[l].B - learning_rate*nn[l].db\n",
    "  return nn\n",
    "\n",
    "def red_neuronal(topology, act_fn):\n",
    "  nn_red = []\n",
    "  L = len(topology)\n",
    "  for i in range(1, L):  \n",
    "    nn_red.append(layer_nn(act_fn[i],topology[i],topology[i-1] ) )  \n",
    "  return nn_red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "q1zzHdlSpeRV"
   },
   "outputs": [],
   "source": [
    "n_x = 12288# -- size of the input layer\n",
    "#n_h = # -- size of the hidden layer\n",
    "n_y = 1# -- size of the output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ySGq43G4pe0p"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data_train= \"Curso_aprendizaje_estadistico/Assesment/dataset/train_catvnoncat.h5\"\n",
    "train_dataset = h5py.File(data_train, \"r\")\n",
    " \n",
    "data_test= \"Curso_aprendizaje_estadistico/Assesment/dataset/test_catvnoncat.h5\"\n",
    "test_dataset = h5py.File(data_test, \"r\")\n",
    "\n",
    "xtrain_classes, xtrain, train_label =\\\n",
    "train_dataset[\"list_classes\"],train_dataset[\"train_set_x\"],train_dataset[\"train_set_y\"]\n",
    "\n",
    "test_classes, xtest,test_label =\\\n",
    "test_dataset[\"list_classes\"],test_dataset[\"test_set_x\"],test_dataset[\"test_set_y\"]\n",
    "\n",
    "xtrain_= np.reshape(xtrain,(209, 64*64*3))/255\n",
    "xtest_ = np.reshape(xtest,(50, 64*64*3))/255\n",
    "\n",
    "topology = [n_x,2,2,3,1]\n",
    "act_fn   = [None,\"relu\", \"relu\", \"relu\",\"sigmoid\" ]\n",
    "\n",
    "nn_red = red_neuronal(topology, act_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "RFhuxjfqpkS5",
    "outputId": "ccd78f8b-f14d-48e1-f507-84da90a6df03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f23d02e6400>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Aini = xtrain_.T\n",
    "Y = np.array(train_label)\n",
    "A, nn = forward_pass(Aini, nn_red)\n",
    "\n",
    "Max_iter = 500\n",
    "J = np.zeros(Max_iter)\n",
    "J[0] = cost_Function(A, np.array(train_label))\n",
    "\n",
    "for i in range(1,Max_iter):\n",
    "  nn = backward_propagation(A, Y, nn)\n",
    "  nn = update_params(nn, 0.005)  \n",
    "  A, nn = forward_pass(Aini, nn)\n",
    "  J[i] = cost_Function(A, np.array(train_label))\n",
    "\n",
    "plt.plot(J,\"ro-\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "8WkrFTaSpkXS"
   },
   "outputs": [],
   "source": [
    "out = A<0.5*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "4aURM6hEVr6c"
   },
   "outputs": [],
   "source": [
    "ones_nn = (out*1==1)\n",
    "Y_nn = (Y==1)\n",
    "zeros_nn = (out*1==0)\n",
    "Y_nn = (Y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhyVpam6WS-u",
    "outputId": "670cfa12-aca7-44bd-8419-93680330a386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.44976076555024\n"
     ]
    }
   ],
   "source": [
    "print((Y_nn==zeros_nn).sum()*100/len(Y_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8uAAhFvXBt3",
    "outputId": "660a9df3-54e1-4e36-f458-3d7748c54ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.55023923444976\n"
     ]
    }
   ],
   "source": [
    "print((Y_nn==ones_nn).sum()*100/len(Y_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Efl9BgIXycz",
    "outputId": "16735e46-4846-4298-9a31-89a57bbd5f88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=3, hidden_layer_sizes=(3, 5, 5), learning_rate_init=0.5,\n",
       "              max_iter=2000, random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = xtrain_\n",
    "y = np.array(train_label)\n",
    "clf = MLPClassifier(solver='lbfgs', learning_rate_init = 0.5, alpha = 3, hidden_layer_sizes=(3,5,5),max_iter = 2000, random_state=1)\n",
    "\n",
    "clf.fit(X, y)\n",
    "#MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEPqy0svaoyg",
    "outputId": "7c6a8e49-11dd-487e-dd5d-8ee3e0ae2bb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.04306220095694"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clf.score(X, y))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(xtest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(xtest_,test_label)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.75561602e-02, 9.62443840e-01],\n",
       "       [1.59275757e-01, 8.40724243e-01],\n",
       "       [2.03329550e-01, 7.96670450e-01],\n",
       "       [6.23140357e-01, 3.76859643e-01],\n",
       "       [6.88328641e-01, 3.11671359e-01],\n",
       "       [2.23263573e-01, 7.76736427e-01],\n",
       "       [9.99627054e-01, 3.72945833e-04],\n",
       "       [2.92946810e-01, 7.07053190e-01],\n",
       "       [3.75624705e-02, 9.62437530e-01],\n",
       "       [1.00830568e-01, 8.99169432e-01],\n",
       "       [7.06749510e-01, 2.93250490e-01],\n",
       "       [2.97594280e-01, 7.02405720e-01],\n",
       "       [7.29198338e-02, 9.27080166e-01],\n",
       "       [8.55435066e-01, 1.44564934e-01],\n",
       "       [9.99955642e-01, 4.43584243e-05],\n",
       "       [1.49342317e-01, 8.50657683e-01],\n",
       "       [9.84364788e-01, 1.56352122e-02],\n",
       "       [3.75710726e-02, 9.62428927e-01],\n",
       "       [9.96413695e-01, 3.58630527e-03],\n",
       "       [9.99971167e-01, 2.88333271e-05],\n",
       "       [4.08168453e-02, 9.59183155e-01],\n",
       "       [8.79211146e-01, 1.20788854e-01],\n",
       "       [9.98981116e-01, 1.01888399e-03],\n",
       "       [6.37584011e-02, 9.36241599e-01],\n",
       "       [1.34580548e-01, 8.65419452e-01],\n",
       "       [2.38329614e-01, 7.61670386e-01],\n",
       "       [9.96317404e-01, 3.68259646e-03],\n",
       "       [9.99139829e-01, 8.60170544e-04],\n",
       "       [9.51934754e-01, 4.80652456e-02],\n",
       "       [5.55318545e-02, 9.44468146e-01],\n",
       "       [8.68927055e-01, 1.31072945e-01],\n",
       "       [1.63265633e-01, 8.36734367e-01],\n",
       "       [2.50830077e-01, 7.49169923e-01],\n",
       "       [2.21578789e-01, 7.78421211e-01],\n",
       "       [5.76730450e-02, 9.42326955e-01],\n",
       "       [9.75118654e-01, 2.48813461e-02],\n",
       "       [9.71955908e-01, 2.80440921e-02],\n",
       "       [4.03271648e-01, 5.96728352e-01],\n",
       "       [8.95920357e-01, 1.04079643e-01],\n",
       "       [9.87350476e-01, 1.26495239e-02],\n",
       "       [3.43167455e-01, 6.56832545e-01],\n",
       "       [9.99882712e-01, 1.17288195e-04],\n",
       "       [1.00100281e-01, 8.99899719e-01],\n",
       "       [9.94091535e-01, 5.90846515e-03],\n",
       "       [3.75561602e-02, 9.62443840e-01],\n",
       "       [8.85031561e-01, 1.14968439e-01],\n",
       "       [8.14654475e-01, 1.85345525e-01],\n",
       "       [3.75561602e-02, 9.62443840e-01],\n",
       "       [3.75648974e-02, 9.62435103e-01],\n",
       "       [9.28756375e-01, 7.12436250e-02]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(xtest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sesion_10_nn_routines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
