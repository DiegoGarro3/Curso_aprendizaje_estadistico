{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/hernansalinas/Curso_aprendizaje_estadistico/blob/main/Assesment/Laboratorio_05_NormalEquations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n"
      ],
      "metadata": {
        "id": "XbRDAmh1Ao85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normal equation\n",
        "Se puede encontrar una solucion exacta para theta sin necesidad de emplear el gradiente descente de la sesiones pasadas, para ellos se puede encontrar el valor minimo de theta y a partir de alli determinar el valor de theta que minimiza J.\n",
        "\n",
        "Los pasos para esta minimizacion se dejan como tarea, y pueden ser calculados según lo siguiente:\n",
        "\n",
        "Si J es la funcion de coste dada por:\n",
        "\n",
        "\\begin{equation}\n",
        "J(\\theta_1,\\theta_2,\\theta_3, ...,\\theta_n )=\\frac{1}{2m} \\sum_{i = 1}^m (\\Theta^{T} X - \\hat{y}^{(i)})^2\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Demostrar que:\n",
        "\n",
        "- $J(\\theta_1,\\theta_2,\\theta_3, ...,\\theta_n ) = \\frac{1}{2m} (\\Theta ^ T X - y^T) (\\Theta ^ T X - y^T)^T$\n",
        "\n",
        "- $J= (\\Theta ^T X) (\\Theta ^T X)^T - 2(\\Theta ^T X)Y  + Y^TY $\n",
        "\n",
        "\n",
        "- $ \\nabla _{\\theta} J = \\frac{1}{m} (2 X(X^T \\Theta) -2XY)$\n",
        "\n",
        "\n",
        "Para encontrar el valor minimo de \\theta,  $\\nabla _{\\theta} J = 0$,\n",
        "\n",
        "- $\\Theta = (X^T X)^{-1} X^T y$\n",
        "\n",
        "\n",
        "\n",
        "En este caso,tenemos que:\n",
        "\n",
        "sea $X \\in R^{n\\times m}$ ,  $X^T \\in R^{m\\times n}$\n",
        "\n",
        "sea $Y \\in R^{m \\times 1}$,  $Y^T \\in R^{1 \\times m}$\n",
        "\n",
        "sea $\\Theta \\in R^{n \\times 1}$, $\\Theta^T \\in R^{1 \\times n}$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Para la demostracion anterior emplee las siguientes propiedades:\n",
        "\n",
        "- $z^T z= \\sum_i z_i^2$\n",
        "- $a^T b = b^Ta$\n",
        "- $\\nabla _x b^T x = b$\n",
        "- $\\nabla _x  x^T A x = 2Ax$\n",
        "\n",
        "donde a, b, x son matrices, $\\nabla_x$ es la derivada respecto al vector x, y A es una matriz simétrica\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LNutRFwDsT-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Para los datos del laboratorio anterior aplicar la ecuacion normal.\n",
        "2. Tomar el dataset de las casas de Boston y construir un modelo de regresión mutivariada.\n",
        "\n",
        "```\n",
        "# Tomar los datos de las casas de boston y hacer una regresion lineal tomando\n",
        "# el average number of rooms per dwelling.\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "df = pd.DataFrame({\"mean_\":target, \"rm\":data[:,5]})\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "ZZyetWq9sWxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intepretación Probabilistica.\n",
        "\n",
        "Supongamos que tenemos una caracteristica $x_i$ con m valores de entrenamiento, si asumimos que cada valor $y_i$ presenta una dispersión gaussiana $\\epsilon_i$, cada $y_i$ podrá tener el siguiente valor:\n",
        "\n",
        "$y^{i} = \\Theta^T X^{(i)} + \\epsilon_i$\n",
        "\n",
        "Asumiendo ademas que el ruido gaussiando es aleatorio y esta distribuido de forma identica, con media cero y varianza $\\sigma$, tenemos que la probabilidad de que la cantidad y tenga  dispersion $\\epsilon_i$ es:\n",
        "\\begin{equation}\n",
        "p(\\epsilon^{(i)})=\\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{ \\left( \\epsilon^{(i)}\\right)^2 }{2\\sigma ^2}}\n",
        "\\end{equation}\n",
        "\n",
        "Escribiendo, lo anterior en terminos de la probabilidad de obtener un valor de $y^{i}$ dado un $x^{i}$ parametrizado por $\\theta$ obtenemos que:\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "p_i(y^{i}|x^{i};\\theta)=\\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{ \\left( y_i - \\Theta^T X^{(i)} \\right)^2 }{2\\sigma ^2}}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "Si ausmimos independencia estadística de cada $\\epsilon^{(i)}$, la probabilidad $L(\\theta)$ asociada a toda la distribución de puntos viene dada por:\n",
        "\n",
        "\\begin{equation}\n",
        "\\cal{L}(\\theta) = p(\\vec{y}|X;\\theta)=\\prod_{i=1}^{n} p_i(y^{i}|x^{i};\\theta)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\cal{L}(\\theta) =\\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{ \\left( y_i - \\Theta^T X^{(i)} \\right)^2 }{2\\sigma ^2}}\n",
        "\\end{equation}\n",
        "\n",
        "para tener la mejor estimación posible de los valores que se deben elegir de  $\\theta$, se escogeran los parámetros que generan la mayor probabilidad de ocurrencia según las observaciones, es decir, aquellos valores para el cual $L(\\theta)$ es máximo, si aplicamos el logaritmo natural antes de máximar tenemos que:\n",
        "\n",
        "\\begin{equation}\n",
        "\\ln \\cal{L}(\\theta) = \\cal{l}(\\theta) = \\ln \\left[\\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{ \\left( y_i - \\Theta^T X^{(i)} \\right)^2 }{2\\sigma ^2}} \\right]\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Después de un par de pasos se puede encontrar que:\n",
        "\n",
        "\\begin{equation}\n",
        "\\cal{l}(\\theta) = n\\ln \\frac{1}{\\sqrt{2\\pi\\sigma}} - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y^{i}-\\Theta^T X^{i})^2\n",
        "\\end{equation},\n",
        "\n",
        "maximar $\\cal{l(\\theta)}$ equivale a encontrar donde  $\\nabla_{\\theta} \\cal{l(\\theta)} = 0$. Lo anterior muestra por que la elección de minimos cuadrados puede ser una buena eleccción para el analisis de los datos."
      ],
      "metadata": {
        "id": "jtlcDPkgsw0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Solución"
      ],
      "metadata": {
        "id": "6ufBPAeRWq6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Para los datos del laboratorio anterior aplicar la ecuacion normal.\n"
      ],
      "metadata": {
        "id": "pMn1qExrWwmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "N=100\n",
        "x_1= 2*np.random.random(N)-1\n",
        "x_2= 2*np.random.random(N)-1\n",
        "y_label = 0.2 * x_1 - 0.5 * x_2 + 0.2*(2*np.random.random(N)-1)\n",
        "\n",
        "df = pd.DataFrame({\"x1\":x_1, \"x2\":x_2, \"y\":y_label})\n",
        "df[\"ones\"]=1\n",
        "\n",
        "X = df[[\"ones\", \"x1\", \"x2\"]].values.T\n",
        "Y = df.y.values\n",
        "\n",
        "\n",
        "Theta = np.linalg.inv(X@X.T)@X@Y\n",
        "\n",
        "print(Theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01hOrNsf9PJy",
        "outputId": "c4d9b2cb-7e6b-439e-e647-df7b9df0f712"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.0128696   0.22207565 -0.52354293]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Tomar el dataset de las casas de Boston y construir un modelo de regresión mutivariada.\n",
        "\n",
        "```\n",
        "# Tomar los datos de las casas de boston y hacer una regresion lineal tomando\n",
        "# el average number of rooms per dwelling.\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "df = pd.DataFrame({\"mean_\":target, \"rm\":data[:,5]})\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "jwLVLBoUWzG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hagamos el modelo de regresión multivariada"
      ],
      "metadata": {
        "id": "V8vHuYm5cSi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mult_value_regression(df1,Y_key):  #Y_key es el nombre la columna que llevas los datos de clasificación\n",
        "\n",
        "  df1.insert(0,'ones',1)\n",
        "  X = df1.drop(Y_key,axis = 1).values.T\n",
        "  Y = df1[Y_key].values\n",
        "\n",
        "  Theta = np.linalg.inv(X@X.T)@X@Y\n",
        "\n",
        "  return Theta\n",
        "\n"
      ],
      "metadata": {
        "id": "8YGyCJS6W8ue"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos para los datos del laboratorio anterior"
      ],
      "metadata": {
        "id": "dpH7ESgAjWEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"x1\":x_1, \"x2\":x_2, \"y\":y_label})\n",
        "\n",
        "theta = mult_value_regression(df,\"y\")\n",
        "theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXT4RMBcf4x8",
        "outputId": "c938a687-4132-4b88-ef6b-337f9364cca9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0128696 ,  0.22207565, -0.52354293])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y lo aplicamos al dataset de las casa de boston"
      ],
      "metadata": {
        "id": "lpwybHASjeRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "df = pd.DataFrame({\"mean_\":target, \"rm\":data[:,5]})\n",
        "\n",
        "theta = mult_value_regression(df,\"rm\")\n",
        "theta\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNvhXnV3hTaG",
        "outputId": "1ac5e940-6008-48a9-cee7-cb947b976be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.08763867, 0.05312235])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}